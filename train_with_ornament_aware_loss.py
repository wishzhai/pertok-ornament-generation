#!/usr/bin/env python3
"""
ä½¿ç”¨OrnamentAwareLossçš„å®Œæ•´è®­ç»ƒè„šæœ¬
ä¸è®ºæ–‡æµç¨‹å›¾å®Œå…¨ä¸€è‡´çš„è®­ç»ƒå®ç°
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, random_split
from pathlib import Path
import pandas as pd
from miditok import PerTok
from tqdm import tqdm
import numpy as np
import os
import time
import argparse
import matplotlib.pyplot as plt

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from ornament_model import OrnamentTransformer
from working_pertok_config import create_working_config
from ornament_aware_loss import OrnamentAwareLoss, create_ornament_aware_loss


class OrnamentDatasetWithAwareLoss:
    """é…åˆOrnamentAwareLossçš„è£…é¥°éŸ³æ•°æ®é›†"""
    
    def __init__(self, maestro_path: str, max_seq_len: int = 512, max_files: int = None):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            maestro_path: MAESTROæ•°æ®é›†è·¯å¾„
            max_seq_len: æœ€å¤§åºåˆ—é•¿åº¦
            max_files: é™åˆ¶æ–‡ä»¶æ•°é‡ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
        """
        self.maestro_path = Path(maestro_path)
        self.max_seq_len = max_seq_len
        
        # ä½¿ç”¨æ­£ç¡®é…ç½®åˆ›å»ºtokenizer
        config = create_working_config()
        self.tokenizer = PerTok(config)
        print(f"âœ… Tokenizeråˆ›å»ºæˆåŠŸï¼Œè¯æ±‡è¡¨å¤§å°: {len(self.tokenizer.vocab)}")
        
        # åŠ è½½MAESTROå…ƒæ•°æ®å¹¶ç­›é€‰å››ä½ä½œæ›²å®¶
        csv_path = self.maestro_path / 'maestro-v3.0.0.csv'
        if not csv_path.exists():
            raise FileNotFoundError(f"MAESTRO CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        
        self.dataset = pd.read_csv(csv_path)
        
        # ç­›é€‰å››ä½canonicalä½œæ›²å®¶ï¼ˆä¸è®ºæ–‡æè¿°ä¸€è‡´ï¼‰
        canonical_composers = [
            'Johann Sebastian Bach',
            'Wolfgang Amadeus Mozart', 
            'Ludwig van Beethoven',
            'FrÃ©dÃ©ric Chopin'
        ]
        
        self.dataset = self.dataset[
            self.dataset['canonical_composer'].isin(canonical_composers)
        ].copy()
        
        print(f"ğŸ“Š ç­›é€‰å‡º{len(self.dataset)}é¦–ä½œå“ (å MAESTROçš„{len(self.dataset)/1276*100:.1f}%)")
        print("ä½œæ›²å®¶åˆ†å¸ƒ:")
        for composer, count in self.dataset['canonical_composer'].value_counts().items():
            print(f"  {composer}: {count}é¦–")
        
        if max_files:
            self.dataset = self.dataset.head(max_files)
            print(f"âš ï¸  é™åˆ¶ä¸ºå‰{max_files}ä¸ªæ–‡ä»¶ç”¨äºå¿«é€Ÿæµ‹è¯•")
            
        self.training_pairs = []
        self._prepare_training_data()
        
    def _prepare_training_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ® - åˆ›å»ºç®€åŒ–â†’è£…é¥°çš„é…å¯¹æ•°æ®"""
        print("ğŸ”„ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        for _, row in tqdm(self.dataset.iterrows(), total=len(self.dataset), desc="å¤„ç†MIDIæ–‡ä»¶"):
            try:
                midi_path = self.maestro_path / row['midi_filename']
                if not midi_path.exists():
                    continue
                
                # ä½¿ç”¨PerTokç¼–ç 
                tokenized_result = self.tokenizer(str(midi_path))
                
                if isinstance(tokenized_result, list):
                    for track_idx, tok_sequence in enumerate(tokenized_result):
                        if hasattr(tok_sequence, 'ids'):
                            original_tokens = tok_sequence.ids
                            
                            # åˆ›å»ºå¤šä¸ªè®­ç»ƒå¯¹ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
                            for start_idx in range(0, len(original_tokens), self.max_seq_len // 2):
                                end_idx = min(start_idx + self.max_seq_len, len(original_tokens))
                                if end_idx - start_idx < 100:  # è·³è¿‡å¤ªçŸ­çš„åºåˆ—
                                    continue
                                    
                                segment = original_tokens[start_idx:end_idx]
                                
                                # åˆ›å»ºç®€åŒ–ç‰ˆæœ¬
                                simplified = self._create_simplified_version(segment)
                                
                                if simplified is not None and len(simplified) > 50:
                                    # ç¡®ä¿åºåˆ—é•¿åº¦ä¸€è‡´
                                    input_tokens = simplified[:self.max_seq_len]
                                    target_tokens = segment[:self.max_seq_len]
                                    
                                    # å¡«å……åˆ°ç›¸åŒé•¿åº¦
                                    if len(input_tokens) < self.max_seq_len:
                                        input_tokens.extend([0] * (self.max_seq_len - len(input_tokens)))
                                    if len(target_tokens) < self.max_seq_len:
                                        target_tokens.extend([0] * (self.max_seq_len - len(target_tokens)))
                                    
                                    self.training_pairs.append({
                                        'input_ids': input_tokens,
                                        'target_ids': target_tokens,
                                        'source': f"{row['midi_filename']}_track_{track_idx}_seg_{start_idx}"
                                    })
                                    
            except Exception as e:
                print(f"âš ï¸  å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ {row.get('midi_filename', 'unknown')}: {e}")
                continue
        
        print(f"âœ… ç”Ÿæˆè®­ç»ƒå¯¹æ•°é‡: {len(self.training_pairs)}")
        
    def _create_simplified_version(self, tokens, removal_ratio=0.2):
        """åˆ›å»ºç®€åŒ–ç‰ˆæœ¬ - ç§»é™¤éƒ¨åˆ†è£…é¥°éŸ³ç›¸å…³tokens"""
        if len(tokens) == 0:
            return None
        
        # è®¡ç®—tokené¢‘ç‡
        from collections import Counter
        token_freq = Counter(tokens)
        
        # è¯†åˆ«å¯èƒ½çš„è£…é¥°éŸ³tokens
        ornament_candidates = set()
        
        # ç½•è§tokensæ›´å¯èƒ½æ˜¯è£…é¥°éŸ³
        rare_threshold = max(1, len(tokens) // 50)
        rare_tokens = set([token for token, freq in token_freq.items() if freq <= rare_threshold])
        ornament_candidates.update(rare_tokens)
        
        # åŸºäºè¯æ±‡è¡¨è¯†åˆ«è£…é¥°éŸ³ç›¸å…³tokens
        vocab_reverse = {v: k for k, v in self.tokenizer.vocab.items()}
        for token_id in tokens:
            if token_id < len(vocab_reverse):
                token_str = vocab_reverse[token_id]
                
                # MicroTiming tokens
                if token_str.startswith('MicroTiming_'):
                    ornament_candidates.add(token_id)
                
                # çŸ­æ—¶å€¼tokens  
                elif token_str.startswith('Duration_'):
                    try:
                        duration_val = float(token_str.replace('Duration_', ''))
                        if duration_val < 0.5:  # çŸ­äºåŠæ‹
                            ornament_candidates.add(token_id)
                    except:
                        pass
                
                # çŸ­æ—¶é—´åç§»tokens
                elif token_str.startswith('TimeShift_'):
                    try:
                        shift_val = float(token_str.replace('TimeShift_', ''))
                        if shift_val < 0.25:  # çŸ­äº1/4æ‹
                            ornament_candidates.add(token_id)
                    except:
                        pass
        
        # æ™ºèƒ½ç§»é™¤
        simplified = []
        removed_count = 0
        target_removal = int(len(tokens) * removal_ratio)
        
        for token in tokens:
            should_remove = False
            
            # ä¼˜å…ˆç§»é™¤è£…é¥°éŸ³å€™é€‰
            if (token in ornament_candidates and 
                removed_count < target_removal and
                token not in [0, 1, 2, 3]):  # ä¿ç•™ç‰¹æ®Štokens
                should_remove = True
                removed_count += 1
            
            if not should_remove:
                simplified.append(token)
        
        return simplified if len(simplified) >= 50 else None
    
    def __len__(self):
        return len(self.training_pairs)
    
    def __getitem__(self, idx):
        item = self.training_pairs[idx]
        return {
            'input_ids': torch.tensor(item['input_ids'], dtype=torch.long),
            'target_ids': torch.tensor(item['target_ids'], dtype=torch.long),
            'attention_mask': torch.ones(len(item['input_ids']), dtype=torch.long)
        }


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    
    def __init__(self, patience: int = 8, min_delta: float = 0.001):
        self.patience = patience
        self.min_delta = min_delta
        self.best_loss = float('inf')
        self.counter = 0
        self.early_stop = False
    
    def __call__(self, val_loss: float) -> bool:
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
            
        if self.counter >= self.patience:
            self.early_stop = True
        
        return self.early_stop


def train_with_ornament_aware_loss(args):
    """ä½¿ç”¨OrnamentAwareLossè®­ç»ƒæ¨¡å‹"""
    print("=" * 70)
    print("ğŸµ ä½¿ç”¨OrnamentAwareLossè®­ç»ƒè£…é¥°éŸ³ç”Ÿæˆæ¨¡å‹")
    print("ğŸ“„ ä¸è®ºæ–‡æµç¨‹å›¾å®Œå…¨ä¸€è‡´çš„å®ç°")
    print("=" * 70)
    
    # è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device.type == 'cuda':
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        torch.cuda.empty_cache()
    
    # åˆ›å»ºæ•°æ®é›†
    print(f"\nğŸ“ åŠ è½½æ•°æ®é›†: {args.data_path}")
    dataset = OrnamentDatasetWithAwareLoss(
        maestro_path=args.data_path,
        max_seq_len=args.max_seq_len,
        max_files=args.max_files
    )
    
    if len(dataset) == 0:
        print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„")
        return
    
    # åˆ›å»ºè®­ç»ƒéªŒè¯é›†åˆ†å‰²
    train_size = int(0.85 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)
    
    print(f"ğŸ“Š è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"ğŸ“Š éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    print(f"ğŸ“Š æ‰¹é‡å¤§å°: {args.batch_size}")
    
    # åˆ›å»ºæ¨¡å‹
    vocab_size = len(dataset.tokenizer.vocab)
    
    if args.resume:
        print(f"\nğŸ”„ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
        checkpoint = torch.load(args.resume, map_location=device)
        model = OrnamentTransformer(
            vocab_size=vocab_size,
            max_seq_len=args.max_seq_len,
            d_model=checkpoint.get('d_model', 512),
            n_heads=8,
            n_layers=8
        ).to(device)
        model.load_state_dict(checkpoint['model_state_dict'])
        start_epoch = checkpoint.get('epoch', 0)
        print(f"âœ… æ¨¡å‹æ¢å¤æˆåŠŸï¼Œä»ç¬¬{start_epoch}è½®ç»§ç»­")
    else:
        print(f"\nğŸ—ï¸  åˆ›å»ºæ–°æ¨¡å‹")
        model = OrnamentTransformer(
            vocab_size=vocab_size,
            max_seq_len=args.max_seq_len,
            d_model=args.d_model,
            n_heads=args.n_heads,
            n_layers=args.n_layers
        ).to(device)
        start_epoch = 0
    
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œè¯æ±‡è¡¨å¤§å°: {vocab_size}")
    print(f"ğŸ“ æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # åˆ›å»ºOrnamentAwareLoss - ä¸è®ºæ–‡å›¾ä¸€è‡´
    print(f"\nğŸ¯ åˆ›å»ºOrnamentAwareLoss")
    criterion = create_ornament_aware_loss(
        tokenizer=dataset.tokenizer,
        base_weight=1.0,
        ornament_boost=args.ornament_boost,
        new_content_boost=args.new_content_boost
    )
    
    # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=args.learning_rate, 
        weight_decay=args.weight_decay
    )
    
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=args.learning_rate,
        total_steps=len(train_loader) * args.epochs,
        pct_start=0.1,
        anneal_strategy='cos'
    )
    
    # æ—©åœæœºåˆ¶
    early_stopping = EarlyStopping(patience=args.patience, min_delta=0.001)
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
    checkpoint_dir = Path("checkpoints_ornament_aware")
    checkpoint_dir.mkdir(exist_ok=True)
    
    # è®­ç»ƒå†å²è®°å½•
    train_losses = []
    val_losses = []
    learning_rates = []
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ {args.epochs} ä¸ªepochs...")
    start_time = time.time()
    
    best_val_loss = float('inf')
    
    for epoch in range(start_epoch, start_epoch + args.epochs):
        epoch_start = time.time()
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        train_steps = 0
        
        train_progress = tqdm(train_loader, desc=f"Epoch {epoch+1}/{start_epoch + args.epochs} è®­ç»ƒ")
        for batch in train_progress:
            input_ids = batch['input_ids'].to(device)
            target_ids = batch['target_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            
            optimizer.zero_grad()
            outputs = model(input_ids, attention_mask=attention_mask)
            
            # ä½¿ç”¨OrnamentAwareLoss
            loss = criterion(outputs, target_ids, input_ids)
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            scheduler.step()
            
            train_loss += loss.item()
            train_steps += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            train_progress.set_postfix({
                'loss': f'{loss.item():.4f}',
                'lr': f'{optimizer.param_groups[0]["lr"]:.2e}'
            })
        
        avg_train_loss = train_loss / train_steps
        train_losses.append(avg_train_loss)
        learning_rates.append(optimizer.param_groups[0]['lr'])
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        val_steps = 0
        
        with torch.no_grad():
            val_progress = tqdm(val_loader, desc=f"Epoch {epoch+1} éªŒè¯")
            for batch in val_progress:
                input_ids = batch['input_ids'].to(device)
                target_ids = batch['target_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                
                outputs = model(input_ids, attention_mask=attention_mask)
                loss = criterion(outputs, target_ids, input_ids)
                
                val_loss += loss.item()
                val_steps += 1
                
                val_progress.set_postfix({
                    'val_loss': f'{loss.item():.4f}'
                })
        
        avg_val_loss = val_loss / val_steps
        val_losses.append(avg_val_loss)
        
        # è·å–è£…é¥°éŸ³ç»Ÿè®¡
        stats = criterion.get_loss_statistics(target_ids)
        
        epoch_time = time.time() - epoch_start
        current_lr = optimizer.param_groups[0]['lr']
        
        # æ‰“å°epochæ€»ç»“
        print(f"\nğŸ“Š Epoch {epoch+1} æ€»ç»“:")
        print(f"   è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}")
        print(f"   éªŒè¯æŸå¤±: {avg_val_loss:.4f}")
        print(f"   å­¦ä¹ ç‡: {current_lr:.2e}")
        print(f"   è£…é¥°éŸ³tokens: {stats['ornament_tokens']}/{stats['non_padding_tokens']} ({stats['ornament_tokens']/max(stats['non_padding_tokens'],1)*100:.1f}%)")
        print(f"   å¹³å‡æƒé‡: {stats['average_weight']:.2f}")
        print(f"   è€—æ—¶: {epoch_time:.1f}s")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_path = checkpoint_dir / "best_ornament_aware_model.pth"
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'config': create_working_config(),
                'vocab_size': vocab_size,
                'epoch': epoch + 1,
                'train_loss': avg_train_loss,
                'val_loss': avg_val_loss,
                'd_model': args.d_model,
                'n_heads': args.n_heads,
                'n_layers': args.n_layers,
                'max_seq_len': args.max_seq_len
            }, best_model_path)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path}")
        
        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % 5 == 0:
            checkpoint_path = checkpoint_dir / f"checkpoint_epoch_{epoch+1}.pth"
            torch.save({
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'config': create_working_config(),
                'vocab_size': vocab_size,
                'epoch': epoch + 1,
                'train_loss': avg_train_loss,
                'val_loss': avg_val_loss,
                'd_model': args.d_model,
                'n_heads': args.n_heads,
                'n_layers': args.n_layers,
                'max_seq_len': args.max_seq_len
            }, checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
        
        # æ—©åœæ£€æŸ¥
        if early_stopping(avg_val_loss):
            print(f"ğŸ›‘ æ—©åœè§¦å‘ (epoch {epoch+1})")
            break
        
        print("-" * 50)
    
    total_time = time.time() - start_time
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    plot_training_history(train_losses, val_losses, learning_rates, checkpoint_dir)
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/3600:.1f}å°æ—¶")
    print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {checkpoint_dir}")
    
    return best_model_path


def plot_training_history(train_losses, val_losses, learning_rates, save_dir):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    epochs = range(1, len(train_losses) + 1)
    
    # æŸå¤±æ›²çº¿
    ax1.plot(epochs, train_losses, 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
    ax1.plot(epochs, val_losses, 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('æŸå¤±')
    ax1.set_title('OrnamentAwareLoss è®­ç»ƒæ›²çº¿')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # å­¦ä¹ ç‡æ›²çº¿
    ax2.plot(epochs, learning_rates, 'g-', label='å­¦ä¹ ç‡', linewidth=2)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('å­¦ä¹ ç‡')
    ax2.set_title('å­¦ä¹ ç‡å˜åŒ–')
    ax2.set_yscale('log')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = save_dir / 'ornament_aware_training_history.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š è®­ç»ƒå†å²å›¾å·²ä¿å­˜: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='ä½¿ç”¨OrnamentAwareLossè®­ç»ƒè£…é¥°éŸ³ç”Ÿæˆæ¨¡å‹')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_path', type=str, default='maestro-v3.0.0-midi/maestro-v3.0.0',
                        help='MAESTROæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--max_files', type=int, default=None,
                        help='é™åˆ¶æ–‡ä»¶æ•°é‡ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--max_seq_len', type=int, default=512,
                        help='æœ€å¤§åºåˆ—é•¿åº¦')
    parser.add_argument('--d_model', type=int, default=512,
                        help='æ¨¡å‹ç»´åº¦')
    parser.add_argument('--n_heads', type=int, default=8,
                        help='æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--n_layers', type=int, default=8,
                        help='Transformerå±‚æ•°')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=30,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=8,
                        help='æ‰¹é‡å¤§å°')
    parser.add_argument('--learning_rate', type=float, default=2e-4,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=0.01,
                        help='æƒé‡è¡°å‡')
    parser.add_argument('--patience', type=int, default=8,
                        help='æ—©åœè€å¿ƒ')
    
    # OrnamentAwareLosså‚æ•°
    parser.add_argument('--ornament_boost', type=float, default=2.5,
                        help='è£…é¥°éŸ³tokenæƒé‡å€æ•°')
    parser.add_argument('--new_content_boost', type=float, default=1.5,
                        help='æ–°å¢å†…å®¹æƒé‡å€æ•°')
    
    # æ¢å¤è®­ç»ƒ
    parser.add_argument('--resume', type=str, default=None,
                        help='ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ')
    
    args = parser.parse_args()
    
    # æ‰“å°é…ç½®
    print("ğŸ”§ è®­ç»ƒé…ç½®:")
    for key, value in vars(args).items():
        print(f"   {key}: {value}")
    
    # å¼€å§‹è®­ç»ƒ
    best_model_path = train_with_ornament_aware_loss(args)
    print(f"\nâœ… è®­ç»ƒå®Œæˆï¼Œæœ€ä½³æ¨¡å‹: {best_model_path}")


if __name__ == "__main__":
    main()
