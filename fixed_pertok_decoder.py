#!/usr/bin/env python3
"""
Fixed PerTok Decoder
- Prioritize PerTok internal decoding (tokens_to_score / _tokens_to_score)
- Fall back to manual decoding with TimeShift / Pitch / Duration / Velocity / MicroTiming
- TPQ read from tokenizer.config.additional_params['ticks_per_quarter'] (default 480)
"""
from __future__ import annotations

import re
from typing import List, Optional

import torch
from miditok import PerTok
from miditok.classes import TokSequence

import symusic
from symusic import Score, Track, Note, Tempo, TimeSignature


class FixedPerTokDecoder:
    """Robust decoder for PerTok token sequences."""

    def __init__(self, tokenizer: PerTok) -> None:
        self.tokenizer = tokenizer
        # Miditok PerTok.vocab: token_str -> id
        self.vocab = tokenizer.vocab
        self.vocab_reverse = {v: k for k, v in self.vocab.items()}  # id -> token_str

        # Read TPQ from tokenizer config (additional_params)
        tpq = 480
        config = getattr(tokenizer, 'config', None)
        if config is not None:
            add_params = getattr(config, 'additional_params', {})
            tpq_raw = add_params.get('ticks_per_quarter', tpq)
            # å®‰å…¨è½¬æ¢TPQ - å¤„ç†å¯èƒ½çš„å­—ç¬¦ä¸²æ ¼å¼é—®é¢˜
            try:
                if isinstance(tpq_raw, str):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œæå–æ•°å­—éƒ¨åˆ†
                    tpq_match = re.search(r'(\d+)', str(tpq_raw))
                    if tpq_match:
                        tpq = int(tpq_match.group(1))
                    else:
                        tpq = 480  # é»˜è®¤å€¼
                else:
                    tpq = int(float(tpq_raw))  # å…ˆè½¬floatå†è½¬intå¤„ç†å°æ•°
            except (ValueError, TypeError):
                print(f"âš ï¸ TPQè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼480: {tpq_raw}")
                tpq = 480
        self.tpq = tpq
        print(f"è§£ç å™¨ä½¿ç”¨TPQ: {self.tpq} (ä¸tokenizeré…ç½®ä¸€è‡´)")

        # MicroTiming params
        self.max_micro_shift_beats = 0.0
        self.num_micro_bins = 0
        if config is not None:
            add_params = getattr(config, 'additional_params', {})
            self.max_micro_shift_beats = float(add_params.get('max_microtiming_shift', 0.0))
            self.num_micro_bins = int(add_params.get('num_microtiming_bins', 0))

        # Token type buckets
        self._analyze_token_types()

    def _analyze_token_types(self) -> None:
        token_types = {
            'special': set(),
            'pitch': set(),
            'velocity': set(),
            'duration': set(),
            'time_shift': set(),
            'microtiming': set(),
            'tempo': set(),
            'time_signature': set(),
            'other': set(),
        }
        for token_str, token_id in self.vocab.items():
            if token_str.startswith('Pitch_'):
                token_types['pitch'].add(token_id)
            elif token_str.startswith('Velocity_'):
                token_types['velocity'].add(token_id)
            elif token_str.startswith('Duration_'):
                token_types['duration'].add(token_id)
            elif token_str.startswith('TimeShift_'):
                token_types['time_shift'].add(token_id)
            elif token_str.startswith('MicroTiming_'):
                token_types['microtiming'].add(token_id)
            elif token_str.startswith('Tempo_'):
                token_types['tempo'].add(token_id)
            elif token_str.startswith('TimeSig_'):
                token_types['time_signature'].add(token_id)
            elif token_str.endswith('_None'):
                token_types['special'].add(token_id)
            else:
                token_types['other'].add(token_id)
        self.token_types = token_types
        print("Tokenç±»å‹åˆ†æå®Œæˆ:")
        for k, s in self.token_types.items():
            print(f"  {k}: {len(s)} tokens")

    # ============== Public API ==============
    def decode_tokens(self, tokens: List[int]) -> Optional[Score]:
        """ä½¿ç”¨çº¯PerTokæ¶æ„è§£ç ï¼ˆä¸¥æ ¼éµå¾ªPerTokè§„èŒƒï¼‰"""
        print(f"ğŸ¯ å¼€å§‹PerTokæ¶æ„è§£ç : {len(tokens)}ä¸ªtokens")
        
        # ç¬¬ä¸€æ­¥ï¼šå°è¯•PerTokå†…éƒ¨è§£ç 
        score = self._decode_strategy_pertok(tokens)
        if score is not None and hasattr(score, 'tracks') and len(score.tracks) > 0:
            print(f"âœ… PerTokå†…éƒ¨è§£ç æˆåŠŸ")
            return score
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨PerTokæ¶æ„çš„æ‰‹åŠ¨è§£ç ï¼ˆè¿™æ˜¯çœŸæ­£çš„PerTokè§£ç ï¼‰
        print(f"âš¡ ä½¿ç”¨PerTokæ¶æ„æ‰‹åŠ¨è§£ç ï¼ˆä¸¥æ ¼éµå¾ªPerTokè§„èŒƒï¼‰")
        score = self._decode_strategy_pertok_architecture(tokens)
        if score is not None and hasattr(score, 'tracks') and len(score.tracks) > 0:
            print(f"âœ… PerTokæ¶æ„è§£ç æˆåŠŸ")
            return score
        
        # ç¬¬ä¸‰æ­¥ï¼šä¼ ç»Ÿæ‰‹åŠ¨è§£ç ä½œä¸ºæœ€åå›é€€
        return self._decode_strategy_manual(tokens)

    def save_to_midi(self, score: Score, output_path: str) -> bool:
        try:
            score.dump_midi(output_path)
            return True
        except Exception as e:
            print(f"ä¿å­˜MIDIå¤±è´¥: {e}")
            return False

    def test_decode(self, tokens: List[int], output_path: str) -> bool:
        score = self.decode_tokens(tokens)
        if score is None:
            print("è§£ç å¤±è´¥")
            return False
        total_notes = sum(len(t.notes) for t in getattr(score, 'tracks', []))
        print(f"è§£ç æˆåŠŸ: {len(getattr(score, 'tracks', []))} è½¨é“, {total_notes} ä¸ªéŸ³ç¬¦")
        if self.save_to_midi(score, output_path):
            print(f"MIDIæ–‡ä»¶å·²ä¿å­˜: {output_path}")
            return True
        return False

    # ============== Strategies ==============
    def _decode_strategy_pertok(self, tokens: List[int]) -> Optional[Score]:
        """Use PerTok internal decoding if possible."""
        print(f"ğŸ” PerTokè§£ç è°ƒè¯•: è¾“å…¥{len(tokens)}ä¸ªtokens")
        
        # Clean and add BOS/EOS if present in vocab
        cleaned: List[int] = []
        vocab_size = max(self.vocab_reverse.keys()) + 1 if self.vocab_reverse else 0
        filtered_count = 0
        for t in tokens:
            if isinstance(t, int) and 0 <= t < vocab_size:
                cleaned.append(t)
            else:
                filtered_count += 1
        
        if filtered_count > 0:
            print(f"  è¿‡æ»¤äº†{filtered_count}ä¸ªæ— æ•ˆtokens")
        
        # æ£€æŸ¥å¿…è¦çš„ç»“æ„tokens
        bos = self.vocab.get('BOS_None')
        eos = self.vocab.get('EOS_None')
        timesig = self.vocab.get('TimeSig_4/4')  # å¸¸è§æ‹å·
        
        print(f"  BOS token: {bos}, EOS token: {eos}, TimeSig token: {timesig}")
        
        # å»é‡ï¼šç§»é™¤é‡å¤çš„BOS/TimeSig/EOS
        cleaned = self._deduplicate_structure_tokens(cleaned)
        
        # ç¡®ä¿åºåˆ—å¼€å¤´æœ‰BOS
        if bos is not None and (len(cleaned) == 0 or cleaned[0] != bos):
            cleaned.insert(0, bos)
            print("  æ·»åŠ äº†BOS token")
        
        # åœ¨BOSåç¡®ä¿æœ‰TimeSig
        if timesig is not None:
            has_timesig = False
            for i in range(min(5, len(cleaned))):  # æ£€æŸ¥å‰5ä¸ªä½ç½®
                token_str = self.vocab_reverse.get(cleaned[i], '')
                if token_str.startswith('TimeSig_'):
                    has_timesig = True
                    break
            if not has_timesig:
                insert_pos = 1 if bos is not None else 0
                cleaned.insert(insert_pos, timesig)
                print("  æ·»åŠ äº†TimeSig token")
        
        # ç¡®ä¿åºåˆ—ç»“å°¾æœ‰EOS
        if eos is not None and (len(cleaned) == 0 or cleaned[-1] != eos):
            cleaned.append(eos)
            print("  æ·»åŠ äº†EOS token")
        
        print(f"  æ¸…ç†å: {len(cleaned)}ä¸ªtokens")
        
        # ä¿®å¤ä¸è§„èŒƒçš„tokenæ ¼å¼ï¼ˆå¦‚ Duration_1.0.320 -> Duration_1.0ï¼‰
        cleaned = self._fix_malformed_tokens(cleaned)
        
        # æ˜¾ç¤ºåºåˆ—å¼€å¤´å‡ ä¸ªtokensç”¨äºè°ƒè¯•
        preview_tokens = []
        for i in range(min(10, len(cleaned))):
            token_str = self.vocab_reverse.get(cleaned[i], f'UNK_{cleaned[i]}')
            preview_tokens.append(token_str)
        print(f"  åºåˆ—é¢„è§ˆ: {' | '.join(preview_tokens)}...")

        tok_seq = TokSequence(ids=cleaned)
        result = None
        
        # Try strategy 1: without programs
        try:
            print("  å°è¯•ç­–ç•¥1: æ— programså‚æ•°")
            if hasattr(self.tokenizer, '_tokens_to_score'):
                result = self.tokenizer._tokens_to_score([tok_seq])
            else:
                result = self.tokenizer.tokens_to_score([tok_seq])
            
            if result is not None:
                track_count = len(getattr(result, 'tracks', []))
                note_count = sum(len(t.notes) for t in getattr(result, 'tracks', []))
                print(f"  ç­–ç•¥1ç»“æœ: {track_count}ä¸ªè½¨é“, {note_count}ä¸ªéŸ³ç¬¦")
                if track_count > 0 and note_count > 0:
                    return result
            else:
                print("  ç­–ç•¥1: è¿”å›None")
        except Exception as e:
            print(f"  ç­–ç•¥1å¼‚å¸¸: {e}")
            result = None
        
        # Try strategy 2: with default programs
        try:
            print("  å°è¯•ç­–ç•¥2: programs=[(0, False)]")
            if hasattr(self.tokenizer, '_tokens_to_score'):
                result = self.tokenizer._tokens_to_score([tok_seq], programs=[(0, False)])
            else:
                result = self.tokenizer.tokens_to_score([tok_seq], programs=[(0, False)])
            
            if result is not None:
                track_count = len(getattr(result, 'tracks', []))
                note_count = sum(len(t.notes) for t in getattr(result, 'tracks', []))
                print(f"  ç­–ç•¥2ç»“æœ: {track_count}ä¸ªè½¨é“, {note_count}ä¸ªéŸ³ç¬¦")
                if track_count > 0 and note_count > 0:
                    return result
            else:
                print("  ç­–ç•¥2: è¿”å›None")
        except Exception as e:
            print(f"  ç­–ç•¥2å¼‚å¸¸: {e}")
            
        print("  âŒ PerTokå†…éƒ¨è§£ç å¤±è´¥")
        return None
    
    def _decode_strategy_pertok_architecture(self, tokens: List[int]) -> Optional[Score]:
        """
        ä½¿ç”¨PerTokæ¶æ„è¿›è¡Œæ‰‹åŠ¨è§£ç 
        è¿™ä¸æ˜¯å›é€€æ–¹æ¡ˆï¼Œè€Œæ˜¯çœŸæ­£çš„PerTokè§£ç ï¼Œä¸¥æ ¼éµå¾ªPerTokçš„tokenè¯­ä¹‰å’Œæ¶æ„
        """
        print("ğŸ—ï¸  PerTokæ¶æ„è§£ç  - ä¸¥æ ¼éµå¾ªPerTok tokenè¯­ä¹‰")
        
        # æ¸…ç†å’Œé¢„å¤„ç†tokens
        cleaned: List[int] = []
        vocab_size = max(self.vocab_reverse.keys()) + 1 if self.vocab_reverse else 0
        for t in tokens:
            if isinstance(t, int) and 0 <= t < vocab_size:
                cleaned.append(t)
        
        # PerTokæ¶æ„è¦æ±‚çš„ç»“æ„åŒ–å¤„ç†
        cleaned = self._deduplicate_structure_tokens(cleaned)
        
        # ç¡®ä¿PerTokå¿…éœ€çš„ç»“æ„tokens
        bos = self.vocab.get('BOS_None')
        eos = self.vocab.get('EOS_None')
        timesig = self.vocab.get('TimeSig_4/4')
        
        if bos is not None and (len(cleaned) == 0 or cleaned[0] != bos):
            cleaned.insert(0, bos)
        
        if timesig is not None:
            has_timesig = False
            for i in range(min(5, len(cleaned))):
                token_str = self.vocab_reverse.get(cleaned[i], '')
                if token_str.startswith('TimeSig_'):
                    has_timesig = True
                    break
            if not has_timesig:
                insert_pos = 1 if bos is not None else 0
                cleaned.insert(insert_pos, timesig)
        
        if eos is not None and (len(cleaned) == 0 or cleaned[-1] != eos):
            cleaned.append(eos)
        
        print(f"  PerTokç»“æ„åŒ–é¢„å¤„ç†å®Œæˆ: {len(cleaned)}ä¸ªtokens")
        
        # åˆ›å»ºScoreå¯¹è±¡ï¼Œä½¿ç”¨PerTokçš„TPQ
        score = Score()
        score.ticks_per_quarter = self.tpq
        track = Track(program=0, is_drum=False, name="PerTokArchitecture")
        
        # PerTokæ¶æ„çš„çŠ¶æ€æœºè§£ç 
        current_time_ticks = 0
        current_velocity = 80
        pending_micro_shift_ticks = 0
        notes = []
        
        print(f"  å¼€å§‹PerTokçŠ¶æ€æœºè§£ç ...")
        
        i = 0
        while i < len(cleaned):
            token_id = cleaned[i]
            token_str = self.vocab_reverse.get(token_id, f'UNK_{token_id}')
            
            # è·³è¿‡ç»“æ„æ€§tokens
            if token_str in ['BOS_None', 'EOS_None'] or token_str.startswith('TimeSig_'):
                i += 1
                continue
            
            # PerTok TimeShiftå¤„ç† - ç›´æ¥ä½¿ç”¨tokenä¸­ç¼–ç çš„ç»å¯¹æ—¶é—´å€¼
            if token_str.startswith('TimeShift_'):
                # PerTokæ ¼å¼: TimeShift_<beats>.<ticks>.<tpq>
                time_value = self._extract_pertok_time(token_str, 'TimeShift_')
                if time_value is not None:
                    current_time_ticks += int(time_value * self.tpq)
                i += 1
                continue
            
            # PerTok MicroTimingå¤„ç†
            if token_str.startswith('MicroTiming_'):
                bin_val = self._extract_int(token_str, prefix='MicroTiming_')
                if bin_val is not None and self.num_micro_bins > 0 and self.max_micro_shift_beats > 0:
                    max_bin = self.num_micro_bins - 1
                    ratio = max(-1.0, min(1.0, (bin_val - max_bin/2) / (max_bin/2)))
                    shift_beats = ratio * self.max_micro_shift_beats
                    pending_micro_shift_ticks = int(shift_beats * self.tpq)
                i += 1
                continue
            
            # PerTok Velocityå¤„ç†
            if token_str.startswith('Velocity_'):
                v = self._extract_int(token_str, prefix='Velocity_')
                if v is not None:
                    current_velocity = max(1, min(int(v), 127))
                i += 1
                continue
            
            # PerTok Pitchå¤„ç† - æ ¸å¿ƒéŸ³ç¬¦åˆ›å»º
            if token_str.startswith('Pitch_'):
                pitch = self._extract_int(token_str, prefix='Pitch_')
                if pitch is not None:
                    # é»˜è®¤å‚æ•°
                    duration_ticks = self.tpq // 4  # é»˜è®¤å››åˆ†éŸ³ç¬¦
                    note_velocity = current_velocity
                    note_micro_shift = pending_micro_shift_ticks

                    # æŸ¥æ‰¾éšåçš„ Velocity / MicroTiming / Durationï¼ˆæ¶ˆè´¹å®ƒä»¬ï¼Œé¿å…äºŒæ¬¡æ¨è¿›æ—¶é—´ï¼‰
                    consumed_until = i
                    look_end = min(i + 8, len(cleaned))
                    for j in range(i + 1, look_end):
                        next_token_str = self.vocab_reverse.get(cleaned[j], '')
                        if next_token_str.startswith('Velocity_') and note_velocity == current_velocity:
                            v = self._extract_int(next_token_str, prefix='Velocity_')
                            if v is not None:
                                note_velocity = max(1, min(int(v), 127))
                            consumed_until = max(consumed_until, j)
                            continue
                        if next_token_str.startswith('MicroTiming_') and note_micro_shift == pending_micro_shift_ticks:
                            bin_val = self._extract_int(next_token_str, prefix='MicroTiming_')
                            if bin_val is not None and self.num_micro_bins > 0 and self.max_micro_shift_beats > 0:
                                max_bin = self.num_micro_bins - 1
                                ratio = max(-1.0, min(1.0, (bin_val - max_bin/2) / (max_bin/2)))
                                shift_beats = ratio * self.max_micro_shift_beats
                                note_micro_shift = int(shift_beats * self.tpq)
                            consumed_until = max(consumed_until, j)
                            continue
                        if next_token_str.startswith('Duration_'):
                            duration_value = self._extract_pertok_time(next_token_str, 'Duration_')
                            if duration_value is not None:
                                duration_ticks = max(1, int(duration_value * self.tpq))
                            consumed_until = max(consumed_until, j)
                            break
                        if next_token_str.startswith('Pitch_'):
                            # ä¸‹ä¸€ä¸ªPitchï¼Œåœæ­¢æŸ¥æ‰¾
                            break

                    # åˆ›å»ºéŸ³ç¬¦ï¼ˆPerTokæ¶æ„çš„æ ¸å¿ƒï¼‰
                    start_ticks = current_time_ticks + note_micro_shift
                    note = Note(
                        time=max(0, start_ticks),
                        duration=duration_ticks,
                        pitch=int(pitch),
                        velocity=note_velocity
                    )
                    notes.append(note)

                    # æŒ‰PerTokè¯­ä¹‰ï¼šæ—¶é—´æ¨è¿›ä»…ç”±åç»­çš„TimeShiftå†³å®šï¼ŒDurationåªå†³å®šéŸ³ç¬¦é•¿åº¦
                    pending_micro_shift_ticks = 0

                    # è·³è¿‡æˆ‘ä»¬å·²æ¶ˆè´¹çš„ Velocity/MicroTiming/Durationï¼ˆä¿ç•™TimeShiftç”±ä¸»å¾ªç¯å¤„ç†ï¼‰
                    i = consumed_until + 1
                    continue
                # pitch è§£æå¤±è´¥åˆ™ç»§ç»­
                i += 1
                continue
            
            # PerTok Durationå¤„ç†ï¼ˆå¦‚æœä¸åœ¨Pitchåï¼‰
            if token_str.startswith('Duration_'):
                # åœ¨PerTokæ¶æ„ä¸­ï¼ŒDurationé€šå¸¸è·ŸéšPitchï¼Œè¿™é‡Œå¯èƒ½æ˜¯ç‹¬ç«‹çš„
                duration_value = self._extract_pertok_time(token_str, 'Duration_')
                if duration_value is not None:
                    # å¯èƒ½è¡¨ç¤ºä¼‘æ­¢ç¬¦æˆ–æ—¶é—´å‰è¿›
                    current_time_ticks += int(duration_value * self.tpq)
                i += 1
                continue
            
            # è·³è¿‡å…¶ä»–token
            i += 1
        
        # å®ŒæˆPerTokæ¶æ„è§£ç 
        if len(notes) > 0:
            track.notes = notes
            score.tracks = [track]
            print(f"  âœ… PerTokæ¶æ„è§£ç å®Œæˆ: {len(notes)}ä¸ªéŸ³ç¬¦")
            return score
        else:
            print(f"  âŒ PerTokæ¶æ„è§£ç å¤±è´¥: æœªç”ŸæˆéŸ³ç¬¦")
            return None
    
    def _extract_pertok_time(self, token_str: str, prefix: str) -> Optional[float]:
        """
        æå–PerTokæ—¶é—´å€¼
        PerTokæ ¼å¼: TimeShift_<beats>.<ticks>.<tpq> æˆ– Duration_<beats>.<ticks>.<tpq>
        """
        if not token_str.startswith(prefix):
            return None
        
        # ç§»é™¤å‰ç¼€
        value_part = token_str[len(prefix):]
        
        # PerTokæ ¼å¼å¯èƒ½æ˜¯ "1.0.320" -> 1.0 beats
        # æˆ–è€…ç®€å•çš„ "1.0" -> 1.0 beats
        parts = value_part.split('.')
        
        try:
            if len(parts) >= 2:
                # "1.0.320" -> æå– "1.0"
                beats = float(f"{parts[0]}.{parts[1]}")
                return beats
            elif len(parts) == 1:
                # "1" -> 1.0
                return float(parts[0])
        except ValueError:
            pass
        
        # å›é€€åˆ°regexæå–
        import re
        m = re.search(r"[-+]?\d*\.\d+|[-+]?\d+", value_part)
        try:
            return float(m.group(0)) if m else None
        except Exception:
            return None

    def _decode_strategy_manual(self, tokens: List[int]) -> Optional[Score]:
        print("âš ï¸  ä½¿ç”¨æ‰‹åŠ¨å›é€€è§£ç ï¼ˆå·²åº”ç”¨ MicroTiming ä¸ TPQï¼‰")
        score = Score()
        score.ticks_per_quarter = self.tpq
        track = Track(program=0, is_drum=False, name="ManualDecoded")

        current_time_ticks = 0
        current_velocity = 64
        pending_micro_shift_ticks = 0

        notes: List[Note] = []
        i = 0
        while i < len(tokens):
            t_id = tokens[i]
            t_str = self.vocab_reverse.get(t_id, '')

            # TimeShift
            if t_id in self.token_types['time_shift']:
                shift_beats = self._extract_float(t_str, prefix='TimeShift_')
                if shift_beats is not None:
                    current_time_ticks += int(shift_beats * self.tpq)
                i += 1
                continue

            # MicroTiming (collect and apply to next note)
            if t_id in self.token_types['microtiming']:
                bin_val = self._extract_int(t_str, prefix='MicroTiming_')
                if bin_val is not None and self.num_micro_bins > 0 and self.max_micro_shift_beats > 0:
                    # Map bin to [-1, 1]
                    max_bin = max(1, self.num_micro_bins // 2)
                    ratio = max(-1.0, min(1.0, float(bin_val) / float(max_bin)))
                    shift_beats = ratio * self.max_micro_shift_beats
                    pending_micro_shift_ticks = int(shift_beats * self.tpq)
                i += 1
                continue

            # Velocity
            if t_id in self.token_types['velocity']:
                v = self._extract_int(t_str, prefix='Velocity_')
                if v is not None:
                    current_velocity = max(1, min(int(v), 127))
                i += 1
                continue

            # Pitch -> create a note using nearest following Duration
            if t_id in self.token_types['pitch']:
                pitch = self._extract_int(t_str, prefix='Pitch_')
                duration_ticks = self.tpq // 4  # default to quarter note
                # Look ahead up to 6 tokens for Duration
                for j in range(i + 1, min(i + 7, len(tokens))):
                    nxt_id = tokens[j]
                    if nxt_id in self.token_types['duration']:
                        d_beats = self._extract_float(self.vocab_reverse.get(nxt_id, ''), prefix='Duration_')
                        if d_beats is not None:
                            duration_ticks = max(1, int(d_beats * self.tpq))
                            break
                start_ticks = current_time_ticks + pending_micro_shift_ticks
                pending_micro_shift_ticks = 0
                if pitch is not None:
                    notes.append(
                        Note(time=max(0, start_ticks), duration=duration_ticks, pitch=int(pitch), velocity=current_velocity)
                    )
                    # advance time by duration for monophonic melody
                    current_time_ticks += duration_ticks
                i += 1
                continue

            # Other tokens: ignore
            i += 1

        track.notes = notes
        score.tracks = [track]
        # Basic musical context
        score.tempos = [Tempo(time=0, mspq=500000)]  # 120 BPM
        score.time_signatures = [TimeSignature(time=0, numerator=4, denominator=4)]

        return score if len(notes) > 0 else None

    # ============== Helpers ==============
    def _extract_float(self, token_str: str, prefix: str) -> Optional[float]:
        # Be robust to tokens like "TimeShift_0.80.320" â†’ extract first float
        if not token_str.startswith(prefix):
            return None
        m = re.search(r"[-+]?\d*\.\d+|[-+]?\d+", token_str[len(prefix):])
        try:
            return float(m.group(0)) if m else None
        except Exception:
            return None

    def _extract_int(self, token_str: str, prefix: str) -> Optional[int]:
        if not token_str.startswith(prefix):
            return None
        m = re.search(r"[-+]?\d+", token_str[len(prefix):])
        try:
            return int(m.group(0)) if m else None
        except Exception:
            return None
    
    def _deduplicate_structure_tokens(self, tokens: List[int]) -> List[int]:
        """å»é™¤é‡å¤çš„ç»“æ„æ€§tokensï¼ˆBOS, TimeSig, EOSï¼‰"""
        cleaned = []
        seen_bos = False
        seen_timesig = False
        
        bos = self.vocab.get('BOS_None')
        eos = self.vocab.get('EOS_None')
        
        for token_id in tokens:
            token_str = self.vocab_reverse.get(token_id, '')
            
            # è·³è¿‡é‡å¤çš„BOS
            if token_id == bos:
                if not seen_bos:
                    cleaned.append(token_id)
                    seen_bos = True
                continue
            
            # åªä¿ç•™ç¬¬ä¸€ä¸ªTimeSig
            if token_str.startswith('TimeSig_'):
                if not seen_timesig:
                    cleaned.append(token_id)
                    seen_timesig = True
                continue
            
            # EOSåªä¿ç•™åœ¨æœ€å
            if token_id == eos:
                continue  # ç¨åç»Ÿä¸€æ·»åŠ 
            
            cleaned.append(token_id)
        
        return cleaned
    
    def _fix_malformed_tokens(self, tokens: List[int]) -> List[int]:
        """ä¿®å¤æ ¼å¼é”™è¯¯çš„tokensï¼ˆå¦‚ Duration_1.0.320 -> Duration_1.0ï¼‰"""
        fixed = []
        fixed_count = 0
        
        for token_id in tokens:
            token_str = self.vocab_reverse.get(token_id, '')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ¼å¼é”™è¯¯çš„tokenï¼ˆåŒ…å«å¤šä¸ªç‚¹æˆ–å¼‚å¸¸æ ¼å¼ï¼‰
            if any(prefix in token_str for prefix in ['Duration_', 'TimeShift_', 'MicroTiming_']) and token_str.count('.') > 1:
                # æå–ç¬¬ä¸€ä¸ªåˆç†çš„æ•°å­—éƒ¨åˆ†
                if token_str.startswith('Duration_'):
                    match = re.search(r'Duration_([-+]?\d*\.?\d+)', token_str)
                    if match:
                        clean_value = match.group(1)
                        new_token_str = f'Duration_{clean_value}'
                        new_token_id = self.vocab.get(new_token_str, token_id)
                        if new_token_id != token_id:
                            fixed.append(new_token_id)
                            fixed_count += 1
                            continue
                
                elif token_str.startswith('TimeShift_'):
                    match = re.search(r'TimeShift_([-+]?\d*\.?\d+)', token_str)
                    if match:
                        clean_value = match.group(1)
                        new_token_str = f'TimeShift_{clean_value}'
                        new_token_id = self.vocab.get(new_token_str, token_id)
                        if new_token_id != token_id:
                            fixed.append(new_token_id)
                            fixed_count += 1
                            continue
                
                elif token_str.startswith('MicroTiming_'):
                    match = re.search(r'MicroTiming_([-+]?\d+)', token_str)
                    if match:
                        clean_value = match.group(1)
                        new_token_str = f'MicroTiming_{clean_value}'
                        new_token_id = self.vocab.get(new_token_str, token_id)
                        if new_token_id != token_id:
                            fixed.append(new_token_id)
                            fixed_count += 1
                            continue
            
            # ä¿æŒåŸtoken
            fixed.append(token_id)
        
        if fixed_count > 0:
            print(f"  ä¿®å¤äº†{fixed_count}ä¸ªæ ¼å¼é”™è¯¯çš„tokens")
        
        return fixed


def create_fixed_decoder(tokenizer_config_func=None) -> FixedPerTokDecoder:
    if tokenizer_config_func is None:
        from working_pertok_config import create_working_config
        config = create_working_config()
    else:
        config = tokenizer_config_func()
    tokenizer = PerTok(config)
    return FixedPerTokDecoder(tokenizer)
