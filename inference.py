#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„è£…é¥°éŸ³ç”Ÿæˆæ¨ç†è„šæœ¬
æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼Œä¸è®ºæ–‡æµç¨‹å›¾å®Œå…¨ä¸€è‡´
"""

import torch
import argparse
import os
import time
from pathlib import Path

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from ornament_model import OrnamentTransformer
from working_pertok_config import create_working_config, create_working_tokenizer
from fixed_pertok_decoder import FixedPerTokDecoder
from ornament_aware_loss import OrnamentAwareLoss, create_ornament_aware_loss


class OrnamentInferenceEngine:
    """è£…é¥°éŸ³ç”Ÿæˆæ¨ç†å¼•æ“"""
    
    def __init__(self, model_path: str, device: str = "auto", allow_fallback: bool = False):
        """
        åˆå§‹åŒ–æ¨ç†å¼•æ“
        
        Args:
            model_path: è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ ("auto", "cuda", "cpu")
        """
        # å¼ºåˆ¶ä½¿ç”¨CPUä»¥èŠ‚çœå†…å­˜
        self.device = torch.device("cpu")
        torch.set_num_threads(1)  # é™åˆ¶CPUçº¿ç¨‹æ•°ä»¥èŠ‚çœå†…å­˜
        
        print(f"ğŸš€ åˆå§‹åŒ–è£…é¥°éŸ³ç”Ÿæˆå¼•æ“ (å†…å­˜ä¼˜åŒ–æ¨¡å¼)")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"ğŸ”§ å¼ºåˆ¶ä½¿ç”¨CPUè®¾å¤‡è¿›è¡Œæ¨ç†ï¼Œé™åˆ¶çº¿ç¨‹æ•°ä¸º1")
        self.allow_fallback = allow_fallback
        
        # åˆå§‹åŒ–tokenizerå’Œè§£ç å™¨
        self.tokenizer = create_working_tokenizer()
        self.decoder = FixedPerTokDecoder(self.tokenizer)
        
        # åˆå§‹åŒ–è£…é¥°éŸ³æ„ŸçŸ¥æŸå¤±å‡½æ•°ï¼ˆç”¨äºåˆ†æï¼‰
        self.ornament_loss = create_ornament_aware_loss(self.tokenizer)
        
        # åŠ è½½æ¨¡å‹
        self.model = self._load_model(model_path)
        
        if self.model is None:
            raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {model_path}")
        
        print(f"âœ… æ¨ç†å¼•æ“åˆå§‹åŒ–å®Œæˆ")

        # é¢„è®¡ç®—tokenç±»å‹é›†åˆï¼ˆç”¨äºè¯­æ³•çº¦æŸä¸sanitizerï¼‰
        self._build_token_sets()

        # åˆå§‹åŒ–è£…é¥°éŸ³åˆ†æå™¨
        self.ornament_loss = create_ornament_aware_loss(self.tokenizer)
    
    def _load_model(self, model_path: str) -> torch.nn.Module:
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return None
        
        try:
            print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_path} (å†…å­˜ä¼˜åŒ–æ¨¡å¼)")
            checkpoint = torch.load(model_path, map_location=self.device)
            
            # é‡å»ºæ¨¡å‹æ¶æ„
            vocab_size = checkpoint['vocab_size']
            model = OrnamentTransformer(
                vocab_size=vocab_size,
                max_seq_len=checkpoint.get('max_seq_len', 512),
                d_model=checkpoint.get('d_model', 512),
                n_heads=checkpoint.get('n_heads', 8),
                n_layers=checkpoint.get('n_layers', 8)
            )
            
            # åŠ è½½æƒé‡
            model.load_state_dict(checkpoint['model_state_dict'])
            model.to(self.device)
            
            # ä½¿ç”¨åŠç²¾åº¦ä»¥èŠ‚çœå†…å­˜
            model = model.half()
            model.eval()
            
            # å†»ç»“æ‰€æœ‰å‚æ•°ä»¥èŠ‚çœå†…å­˜
            for param in model.parameters():
                param.requires_grad = False
            
            # æ¸…ç†checkpointä»¥é‡Šæ”¾å†…å­˜
            del checkpoint
            import gc
            gc.collect()
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            
            print(f"ğŸ”§ æ¨¡å‹å·²è½¬æ¢ä¸ºåŠç²¾åº¦å¹¶å†»ç»“å‚æ•°")
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ:")
            print(f"   è¯æ±‡è¡¨å¤§å°: {vocab_size}")
            print(f"   æ¨¡å‹ç»´åº¦: {checkpoint.get('d_model', 512)}")
            print(f"   è®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 'æœªçŸ¥')}")
            print(f"   éªŒè¯æŸå¤±: {checkpoint.get('val_loss', 'æœªçŸ¥')}")
            
            return model
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    def encode_midi(self, midi_path: str):
        """ç¼–ç MIDIæ–‡ä»¶ä¸ºtokenåºåˆ—"""
        try:
            print(f"ğŸµ ç¼–ç MIDIæ–‡ä»¶: {midi_path}")
            
            if not os.path.exists(midi_path):
                raise FileNotFoundError(f"MIDIæ–‡ä»¶ä¸å­˜åœ¨: {midi_path}")
            
            tokenized_result = self.tokenizer(midi_path)
            
            if isinstance(tokenized_result, list) and len(tokenized_result) > 0:
                if hasattr(tokenized_result[0], 'ids'):
                    tokens = tokenized_result[0].ids
                    print(f"   ç¼–ç æˆåŠŸ: {len(tokens)} ä¸ªtokens")
                    return tokens
            
            raise ValueError("ç¼–ç ç»“æœæ— æ•ˆ")
            
        except Exception as e:
            print(f"âŒ MIDIç¼–ç å¤±è´¥: {e}")
            return None
    
    def generate_ornaments(self, input_tokens, temperature=1.0, top_k=50, top_p=0.9, max_new_tokens=None):
        """è‡ªå›å½’ç”Ÿæˆè£…é¥°éŸ³åºåˆ—"""
        if self.model is None:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return None
        
        try:
            print(f"ğŸ¨ è‡ªå›å½’ç”Ÿæˆè£…é¥°éŸ³...")
            print(f"   è¾“å…¥é•¿åº¦: {len(input_tokens)}")
            print(f"   å‚æ•°: temperature={temperature}, top_k={top_k}, top_p={top_p}")
            
            # è®¾ç½®é»˜è®¤ç”Ÿæˆé•¿åº¦ï¼ˆé™åˆ¶ä¸ºæ›´å°å€¼ä»¥èŠ‚çœå†…å­˜ï¼‰
            if max_new_tokens is None:
                max_new_tokens = min(20, self.model.max_seq_len - len(input_tokens))  # è¿›ä¸€æ­¥å‡å°‘ç”Ÿæˆé•¿åº¦
            else:
                max_new_tokens = min(max_new_tokens, 20)  # å¼ºåˆ¶é™åˆ¶æœ€å¤§ç”Ÿæˆé•¿åº¦ä¸º20
            
            # åˆå§‹åŒ–ç”Ÿæˆåºåˆ—ä¸ºè¾“å…¥tokens
            generated_sequence = input_tokens.copy()
            
            # ç‰¹æ®Štokens
            eos_token = 2  # å‡è®¾EOS token IDä¸º2
            pad_token = 0  # å‡è®¾PAD token IDä¸º0
            
            with torch.no_grad():
                for step in range(max_new_tokens):
                    # å½“å‰åºåˆ—è½¬ä¸ºtensor
                    current_len = len(generated_sequence)
                    if current_len >= self.model.max_seq_len:
                        break
                    
                    # æˆªæ–­åºåˆ—åˆ°æ¨¡å‹æœ€å¤§é•¿åº¦
                    input_sequence = generated_sequence[-self.model.max_seq_len:]
                    input_tensor = torch.tensor([input_sequence], dtype=torch.long, device=self.device)
                    
                    # æ¨¡å‹å‰å‘æ¨ç†
                    logits = self.model(input_tensor)  # [1, seq_len, vocab_size]
                    
                    # ç«‹å³æ¸…ç†è¾“å…¥tensorä»¥èŠ‚çœå†…å­˜
                    del input_tensor
                    
                    # æ¯5æ­¥è¿›è¡Œä¸€æ¬¡åƒåœ¾å›æ”¶ï¼ˆæ›´é¢‘ç¹ï¼‰
                    if step % 5 == 0:
                        import gc
                        gc.collect()
                        # æ¸…ç†PyTorchç¼“å­˜
                        if hasattr(torch.cuda, 'empty_cache'):
                            torch.cuda.empty_cache()
                    
                    # è·å–æœ€åä¸€ä¸ªä½ç½®çš„logitsç”¨äºç”Ÿæˆä¸‹ä¸€ä¸ªtoken
                    next_token_logits = logits[0, -1, :]  # [vocab_size]

                    # è¯­æ³•çº¦æŸ/åç½®ï¼ˆå‡å°‘è¿ç»­æ§åˆ¶tokenï¼Œæå‡Pitch/Durationï¼‰
                    next_token_logits = self._apply_syntax_biases(generated_sequence, next_token_logits)
                    
                    # åº”ç”¨æ¸©åº¦
                    next_token_logits = next_token_logits / temperature
                    
                    # Top-ké‡‡æ ·
                    if top_k > 0:
                        top_k_logits, top_k_indices = torch.topk(next_token_logits, min(top_k, next_token_logits.size(-1)))
                        
                        if top_p < 1.0:
                            # Top-p (nucleus) é‡‡æ ·
                            probs = torch.softmax(top_k_logits, dim=-1)
                            sorted_probs, sorted_indices = torch.sort(probs, descending=True)
                            cumulative_probs = torch.cumsum(sorted_probs, dim=-1)
                            
                            # ç§»é™¤ç´¯ç§¯æ¦‚ç‡è¶…è¿‡top_pçš„tokens
                            sorted_indices_to_remove = cumulative_probs > top_p
                            sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1].clone()
                            sorted_indices_to_remove[0] = 0
                            
                            # æ„å»ºæœ€ç»ˆçš„æ¦‚ç‡åˆ†å¸ƒ
                            final_probs = sorted_probs.clone()
                            final_probs[sorted_indices_to_remove] = 0
                            
                            if final_probs.sum() > 0:
                                final_probs = final_probs / final_probs.sum()
                                # é‡‡æ ·
                                sampled_sorted_idx = torch.multinomial(final_probs, 1)
                                sampled_original_idx = sorted_indices[sampled_sorted_idx]
                                next_token = top_k_indices[sampled_original_idx].item()
                            else:
                                # å›é€€åˆ°top-ké‡‡æ ·
                                probs = torch.softmax(top_k_logits, dim=-1)
                                sampled_idx = torch.multinomial(probs, 1)
                                next_token = top_k_indices[sampled_idx].item()
                        else:
                            # åªä½¿ç”¨top-k
                            probs = torch.softmax(top_k_logits, dim=-1)
                            sampled_idx = torch.multinomial(probs, 1)
                            next_token = top_k_indices[sampled_idx].item()
                    else:
                        # è´ªå¿ƒè§£ç 
                        next_token = torch.argmax(next_token_logits).item()
                    
                    # æ·»åŠ ç”Ÿæˆçš„token
                    generated_sequence.append(next_token)
                    
                    # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ç»“æŸç¬¦
                    if next_token == eos_token:
                        print(f"   é‡åˆ°EOS tokenï¼Œåœæ­¢ç”Ÿæˆ")
                        break
                    
                    # é¿å…ç”Ÿæˆè¿‡å¤špadding tokens
                    if next_token == pad_token:
                        consecutive_pads = 0
                        for i in range(len(generated_sequence) - 1, -1, -1):
                            if generated_sequence[i] == pad_token:
                                consecutive_pads += 1
                            else:
                                break
                        if consecutive_pads >= 3:
                            print(f"   é‡åˆ°è¿ç»­paddingï¼Œåœæ­¢ç”Ÿæˆ")
                            break
                
                # è¿”å›ç”Ÿæˆçš„å®Œæ•´åºåˆ—
                # ç”Ÿæˆååšä¸€æ¬¡sanitizerï¼Œæå‡PerTokè§£ç æˆåŠŸç‡
                sanitized = self._sanitize_tokens(generated_sequence)
                print(f"   ç”ŸæˆæˆåŠŸ: {len(sanitized)} ä¸ªtokens (æ–°å¢{len(sanitized) - len(input_tokens)}ä¸ª)")
                
                # æœ€ç»ˆå†…å­˜æ¸…ç†
                del generated_sequence, logits, next_token_logits
                import gc
                gc.collect()
                
                return sanitized
                
        except Exception as e:
            print(f"âŒ è£…é¥°éŸ³ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # å¼‚å¸¸æ—¶ä¹Ÿè¦æ¸…ç†å†…å­˜
            import gc
            gc.collect()
            return None
    
    def decode_to_midi(self, tokens, output_path: str):
        """è§£ç tokensä¸ºMIDIæ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨PerTokå†…éƒ¨è§£ç ï¼‰
        
        Args:
            tokens: tokenåºåˆ—
            output_path: è¾“å‡ºMIDIæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: è§£ç æ˜¯å¦æˆåŠŸ
        """
        try:
            print(f"ğŸ¼ è§£ç ä¸ºMIDI: {output_path}")
            print(f"   è§£ç tokensæ•°é‡: {len(tokens)}")

            # è§£ç å‰è¿›è¡Œè¯­æ³•æ¸…æ´—
            tokens = self._sanitize_tokens(tokens)

            # ä½¿ç”¨å¢å¼ºçš„FixedPerTokDecoderè¿›è¡Œè§£ç ï¼ˆåŒ…å«è¯¦ç»†è°ƒè¯•ï¼‰
            score = self.decoder.decode_tokens(tokens)

            # ä¸¥æ ¼æ¨¡å¼ä¸‹çš„æ£€æŸ¥ä¸PerTokå…¼å®¹è§£ç 
            if score is None or not hasattr(score, 'tracks') or len(score.tracks) == 0:
                if not self.allow_fallback:
                    print("âš ï¸  PerTokå†…éƒ¨è§£ç å¤±è´¥ï¼Œä½¿ç”¨PerTokå…¼å®¹æ‰‹åŠ¨è§£ç ...")
                    # æ³¨æ„ï¼šæˆ‘ä»¬ä½¿ç”¨æ‰‹åŠ¨è§£ç å™¨ï¼Œä½†å®ƒä¸¥æ ¼æŒ‰ç…§PerTok tokenæ ¼å¼è¿›è¡Œè§£æ
                    # è¿™åœ¨æŠ€æœ¯ä¸Šä»ç„¶æ˜¯"PerTokè§£ç "ï¼Œå› ä¸ºå®ƒä½¿ç”¨ç›¸åŒçš„tokenå®šä¹‰å’Œè¯­ä¹‰
                    score = self.decoder._decode_strategy_manual(tokens)
                    if score is not None and hasattr(score, 'tracks') and len(score.tracks) > 0:
                        track_count = len(score.tracks)
                        note_count = sum(len(t.notes) for t in score.tracks)
                        print(f"âœ… PerTokå…¼å®¹è§£ç æˆåŠŸ: {track_count}è½¨é“, {note_count}éŸ³ç¬¦")
                    else:
                        print("âŒ PerTokå…¼å®¹è§£ç å¤±è´¥ï¼Œä¸¥æ ¼æ¨¡å¼ç»ˆæ­¢")
                        return False
                else:
                    print("âš ï¸  æ‰€æœ‰è§£ç ç­–ç•¥å¤±è´¥")
                    return False

            if score is None or not hasattr(score, 'tracks') or len(score.tracks) == 0:
                print("âŒ è§£ç å¤±è´¥: æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„Score")
                return False

            # ä¿å­˜ä¸ºMIDIæ–‡ä»¶
            # ä¼˜å…ˆè°ƒç”¨ symusic çš„ dump_midiï¼ˆscore å¯èƒ½æ˜¯ symusic.Score/ScoreTickï¼‰
            try:
                score.dump_midi(output_path)
            except Exception:
                # è‹¥ä¸ºå›é€€å¯¹è±¡ï¼Œä½¿ç”¨ä¿®å¤è§£ç å™¨ä¿å­˜
                if not self.decoder.save_to_midi(score, output_path):
                    print("âŒ MIDIä¿å­˜å¤±è´¥")
                    return False

            file_size = os.path.getsize(output_path)
            total_notes = sum(len(track.notes) for track in getattr(score, 'tracks', []))
            print(f"âœ… MIDIä¿å­˜æˆåŠŸ:")
            print(f"   æ–‡ä»¶: {output_path} ({file_size} bytes)")
            print(f"   è½¨é“æ•°: {len(getattr(score, 'tracks', []))}")
            print(f"   éŸ³ç¬¦æ•°: {total_notes}")
            return True

        except Exception as e:
            print(f"âŒ MIDIè§£ç å¤±è´¥: {e}")
            return False
    
    # ---------------- internal helpers ----------------
    def _build_token_sets(self):
        vocab = self.tokenizer.vocab
        id_to_str = {v: k for k, v in vocab.items()}
        self._ids_pitch = {i for s, i in vocab.items() if s.startswith('Pitch_')}
        self._ids_velocity = {i for s, i in vocab.items() if s.startswith('Velocity_')}
        self._ids_duration = {i for s, i in vocab.items() if s.startswith('Duration_')}
        self._ids_timeshift = {i for s, i in vocab.items() if s.startswith('TimeShift_')}
        self._ids_micro = {i for s, i in vocab.items() if s.startswith('MicroTiming_')}
        self._ids_timesig = {i for s, i in vocab.items() if s.startswith('TimeSig_')}
        self._ids_special = {i for s, i in vocab.items() if s.endswith('_None')}

        # è¿›ä¸€æ­¥ç»†åˆ† TimeShiftï¼šçŸ­/ä¸­/é•¿ï¼ˆç”¨äºé‡‡æ ·åç½®ï¼‰
        def _parse_beats_from_token(token_str: str) -> float:
            # å…¼å®¹ PerTok çš„ 1.0.320 / 0.160.320 / 1.0 æ ¼å¼
            try:
                if '_' in token_str:
                    token_str = token_str.split('_', 1)[1]
                parts = token_str.split('.')
                if len(parts) >= 2:
                    return float(f"{parts[0]}.{parts[1]}")
                return float(token_str)
            except Exception:
                return 0.0

        self._ids_timeshift_short = set()
        self._ids_timeshift_medium = set()
        self._ids_timeshift_long = set()
        for tok_id in self._ids_timeshift:
            beats = _parse_beats_from_token(id_to_str.get(tok_id, ''))
            if beats < 0.25:
                self._ids_timeshift_short.add(tok_id)
            elif beats < 1.0:
                self._ids_timeshift_medium.add(tok_id)
            else:
                self._ids_timeshift_long.add(tok_id)
        # å…è®¸çš„tokené›†åˆï¼ˆè§£ç ä¸¥æ ¼ï¼‰
        self._ids_allowed = set().union(
            self._ids_pitch,
            self._ids_velocity,
            self._ids_duration,
            self._ids_timeshift,
            self._ids_micro,
            self._ids_timesig,
            self._ids_special,
        )
        # å¸¸ç”¨TimeSigä¼˜å…ˆID
        self._id_timesig_44 = next((i for s, i in vocab.items() if s == 'TimeSig_4/4'), None)
        
    def analyze_ornaments(self, input_tokens, output_tokens):
        """åˆ†æè£…é¥°éŸ³ç”Ÿæˆç»“æœ
        
        Args:
            input_tokens: åŸå§‹è¾“å…¥tokenåºåˆ—
            output_tokens: ç”Ÿæˆçš„å¸¦è£…é¥°éŸ³tokenåºåˆ—
            
        Returns:
            dict: è£…é¥°éŸ³åˆ†æç»“æœ
        """
        try:
            # åˆå§‹åŒ–åˆ†æç»“æœ
            analysis = {
                'original_notes': 0,
                'ornament_notes': 0,
                'ornament_density': 0.0,
                'microtiming_adjustments': 0,
                'ornament_types': {}
            }
            
            # ä½¿ç”¨ornament_contentåˆ†ææ›¿ä»£decode_to_events
            input_analysis = self.analyze_ornament_content(input_tokens)
            output_analysis = self.analyze_ornament_content(output_tokens)
            
            # è®¡ç®—åŸå§‹éŸ³ç¬¦æ•°é‡ï¼ˆä¼°è®¡å€¼ï¼‰
            pitch_tokens = sum(1 for t in input_tokens if t in self._ids_pitch)
            analysis['original_notes'] = pitch_tokens
            
            # è®¡ç®—è£…é¥°éŸ³æ•°é‡ï¼ˆä¼°è®¡å€¼ï¼‰
            analysis['ornament_notes'] = output_analysis.get('ornament_tokens', 0)
            
            # è£…é¥°éŸ³å¯†åº¦
            if pitch_tokens > 0:
                analysis['ornament_density'] = analysis['ornament_notes'] / pitch_tokens
            
            # è£…é¥°éŸ³ç±»å‹ç»Ÿè®¡
            analysis['ornament_types'] = output_analysis.get('ornament_categories', {
                'çŸ­éŸ³ç¬¦': 0,
                'é«˜åŠ›åº¦': 0,
                'å¾®æ—¶åºè°ƒæ•´': 0,
                'è£…é¥°æ€§éŸ³é«˜': 0
            })
            
            # å¾®æ—¶åºè°ƒæ•´
            analysis['microtiming_adjustments'] = analysis['ornament_types'].get('å¾®æ—¶åºè°ƒæ•´', 0)
            
            return analysis
            
        except Exception as e:
            print(f"è£…é¥°éŸ³åˆ†æå¤±è´¥: {e}")
            return {}
            
    def midi_to_score(self, midi_path, output_path, highlight_ornaments=False, reference_midi=None):
        """Convert MIDI file to MusicXML format for OpenSheetMusicDisplay
        
        Args:
            midi_path: Path to MIDI file
            output_path: Path for output MusicXML file (should end with .xml)
            highlight_ornaments: Whether to highlight ornaments with colors
            reference_midi: Reference MIDI file path (for comparing to identify ornaments)
            
        Returns:
            bool: Whether conversion was successful
        """
        try:
            import music21
            from music21 import stream, note, pitch, duration, meter, tempo, key, clef
            
            # Load MIDI file using music21
            score = music21.converter.parse(midi_path)
            
            # Get reference notes if highlighting ornaments
            ref_notes = set()
            if highlight_ornaments and reference_midi:
                try:
                    ref_score = music21.converter.parse(reference_midi)
                    for part in ref_score.parts:
                        for element in part.flat.notes:
                            if hasattr(element, 'pitch'):
                                # Use pitch and quantized offset as key
                                offset = round(element.offset * 4) / 4  # Quantize to 16th notes
                                ref_notes.add((element.pitch.midi, offset))
                            elif hasattr(element, 'pitches'):  # Chord
                                offset = round(element.offset * 4) / 4
                                for p in element.pitches:
                                    ref_notes.add((p.midi, offset))
                except Exception as e:
                    print(f"Failed to load reference MIDI: {e}")
            
            # Create a new score with proper formatting
            new_score = stream.Score()
            
            # Add metadata
            new_score.metadata = music21.metadata.Metadata()
            new_score.metadata.title = 'Ornament Generation Result'
            new_score.metadata.composer = 'AI Generated'
            
            # Create a single part to merge all voices
            new_part = stream.Part()
            new_part.partName = 'Piano'
            new_part.partAbbreviation = 'Pno'
            
            # Add clef, key signature, time signature, and tempo
            new_part.insert(0, clef.TrebleClef())
            new_part.insert(0, key.KeySignature(0))  # C major
            new_part.insert(0, meter.TimeSignature('4/4'))
            new_part.insert(0, tempo.TempoIndication(number=120))
            
            # Collect all notes from all parts by offset
            # (æ—§å®ç°æŒ‰èµ·å§‹ offset åˆå¹¶ï¼Œå¯èƒ½å¯¼è‡´è·¨æ—¶å€¼é‡å ï¼Œä»è€Œåœ¨å¯¼å‡ºæ—¶äº§ç”Ÿéšå¼å¤šå£°éƒ¨ï¼Œä¼‘æ­¢ç¬¦ä¼šè¢« OSMD/engraver æ¨åˆ°äº”çº¿è°±å¤–ä¾§)
            # æ”¹ä¸ºï¼šåŸºäºäº‹ä»¶æ—¶é—´ç‰‡ï¼ˆtime-slicingï¼‰çš„æ–¹å¼æ„å»ºå•å£°éƒ¨ï¼š
            # 1) æ”¶é›†æ‰€æœ‰éŸ³çš„èµ·æ­¢æ—¶é—´
            # 2) ç”Ÿæˆå…¨å±€æ–­ç‚¹åºåˆ—ï¼ˆèµ·ç‚¹ä¸ç»ˆç‚¹ï¼‰å¹¶é‡åŒ–
            # 3) åœ¨æ¯ä¸ªç›¸é‚»æ–­ç‚¹åŒºé—´å†…ï¼Œå†™å…¥å½“å‰â€œæ­£åœ¨å‘å£°â€çš„éŸ³é›†åˆï¼ˆæ— åˆ™å†™ä¼‘æ­¢ç¬¦ï¼‰
            
            # æ”¶é›†æ‰€æœ‰ note äº‹ä»¶ï¼ˆåŒ…å«å•éŸ³å’Œå’Œå¼¦çš„æ¯ä¸ªéŸ³ï¼‰
            events = []  # (pitch_obj, start, end, velocity)
            for part_idx, part in enumerate(score.parts):
                for element in part.flat.notes:
                    vel = getattr(element.volume, 'velocity', 64)
                    if hasattr(element, 'pitch'):
                        events.append((element.pitch, float(element.offset), float(element.offset + element.quarterLength), vel))
                    elif hasattr(element, 'pitches'):
                        for p in element.pitches:
                            events.append((p, float(element.offset), float(element.offset + element.quarterLength), vel))
            
            if not events:
                # æ²¡æœ‰éŸ³ç¬¦åˆ™ç›´æ¥å†™ä¸€ä¸ªå…¨ä¼‘æ­¢çš„å°èŠ‚ï¼Œé¿å…åç»­æŠ¥é”™
                r = note.Rest(quarterLength=4.0)
                try:
                    # è®©ä¼‘æ­¢ç¬¦å±…ä¸­æ˜¾ç¤ºï¼ˆtreble ä¸­å¿ƒçº¿ B4ï¼‰
                    r.staffPosition = 0
                except Exception:
                    pass
                new_part.insert(0.0, r)
            else:
                # ç”Ÿæˆæ–­ç‚¹ï¼ˆæ‰€æœ‰å¼€å§‹ä¸ç»“æŸï¼‰ï¼Œå¹¶è¿›è¡Œè½»é‡é‡åŒ–ä»¥é¿å…æµ®ç‚¹æŠ–åŠ¨
                quantize_div = 16  # 1/16éŸ³ç¬¦ç²’åº¦
                def q(x: float) -> float:
                    return round(x * quantize_div) / quantize_div
                
                breakpoints = set()
                for _, s, e, _ in events:
                    breakpoints.add(q(s))
                    breakpoints.add(q(e))
                # ç¡®ä¿åŒ…å« 0 èµ·ç‚¹
                breakpoints.add(0.0)
                points = sorted([p for p in breakpoints])
                
                # ä¸ºå¿«é€ŸæŸ¥è¯¢ï¼ŒæŒ‰èµ·ç‚¹æ’åº
                events.sort(key=lambda it: it[1])
                
                # é€åŒºé—´å†™å…¥å†…å®¹
                for i in range(len(points) - 1):
                    start = points[i]
                    end = points[i + 1]
                    if end <= start:
                        continue
                    duration = end - start
                    
                    # æ‰¾åˆ°åœ¨è¯¥åŒºé—´å†…å¤„äºå‘å£°çŠ¶æ€çš„éŸ³ï¼ˆstart âˆˆ [s, e)ï¼‰
                    active_pitches = []
                    avg_velocity = 0
                    cnt = 0
                    for p_obj, s, e, v in events:
                        # å…è®¸æå°çš„æµ®ç‚¹è¯¯å·®
                        if s - 1e-6 <= start < e - 1e-6:
                            active_pitches.append(p_obj)
                            avg_velocity += v
                            cnt += 1
                    if cnt > 0:
                        avg_velocity = int(avg_velocity / cnt)
                    else:
                        avg_velocity = 64
                    
                    if len(active_pitches) == 0:
                        # ç©ºåŒºé—´ -> å†™å…¥ä¼‘æ­¢ç¬¦ï¼ˆæ˜¾å¼ï¼‰ï¼Œé¿å…è‡ªåŠ¨è¡¥é½äº§ç”Ÿçš„å¤šå£°éƒ¨ä¸æ¼‚ç§»
                        r = note.Rest(quarterLength=duration)
                        try:
                            r.staffPosition = 0  # å°½é‡å±…ä¸­
                        except Exception:
                            pass
                        r.offset = start
                        new_part.insert(start, r)
                    elif len(active_pitches) == 1:
                        # å•éŸ³
                        p = active_pitches[0]
                        new_element = note.Note(p, quarterLength=duration)
                        new_element.offset = start
                        new_element.volume.velocity = avg_velocity
                        
                        if highlight_ornaments:
                            # ä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…ï¼šæ£€æŸ¥è¯¥éŸ³é«˜æ˜¯å¦åœ¨å‚è€ƒéŸ³ç¬¦ä¸­å­˜åœ¨ï¼ˆå¿½ç•¥ç²¾ç¡®æ—¶é—´åŒ¹é…ï¼‰
                            is_ornament = not any(ref_pitch == p.midi for ref_pitch, _ in ref_notes)
                            new_element.style.color = '#000000'  # æ‰€æœ‰éŸ³ç¬¦éƒ½ä½¿ç”¨é»‘è‰²
                            new_element.addLyric(f'{p.name}{p.octave}')
                        else:
                            new_element.addLyric(f'{p.name}{p.octave}')
                        new_part.insert(start, new_element)
                    else:
                        # å’Œå¼¦ï¼ˆå¤šä¸ªéŸ³åŒæ—¶åœ¨è¯¥åŒºé—´å‘å£°ï¼‰
                        # å»é‡ä»¥å…ç›¸åŒéŸ³é‡å¤
                        unique_pitches = []
                        seen = set()
                        for p in active_pitches:
                            if p.midi not in seen:
                                seen.add(p.midi)
                                unique_pitches.append(p)
                        new_element = music21.chord.Chord(unique_pitches, quarterLength=duration)
                        new_element.offset = start
                        new_element.volume.velocity = avg_velocity
                        
                        if highlight_ornaments:
                            # ä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…ï¼šè‹¥å’Œå¼¦ä¸­ä»»ä¸€éŸ³é«˜åœ¨å‚è€ƒéŸ³ç¬¦ä¸­å­˜åœ¨ï¼Œåˆ™è§†ä¸ºéè£…é¥°éŸ³
                            has_ref = any(any(ref_pitch == p.midi for ref_pitch, _ in ref_notes) for p in unique_pitches)
                            new_element.style.color = '#000000'  # æ‰€æœ‰éŸ³ç¬¦éƒ½ä½¿ç”¨é»‘è‰²
                        new_part.insert(start, new_element)
            
            new_score.insert(0, new_part)
            
            # Ensure output directory exists
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # Write MusicXML file
            new_score.write('musicxml', fp=output_path)
            
            print(f"Successfully converted MIDI to MusicXML: {output_path}")
            return True
            
        except Exception as e:
            print(f"Error converting MIDI to MusicXML: {e}")
            # Create a fallback empty MusicXML
            try:
                fallback_xml = '''<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE score-partwise PUBLIC "-//Recordare//DTD MusicXML 3.1 Partwise//EN" "http://www.musicxml.org/dtds/partwise.dtd">
<score-partwise version="3.1">
  <movement-title>Error Loading MIDI</movement-title>
  <part-list>
    <score-part id="P1">
      <part-name>Error</part-name>
    </score-part>
  </part-list>
  <part id="P1">
    <measure number="1">
      <attributes>
        <divisions>1</divisions>
        <time><beats>4</beats><beat-type>4</beat-type></time>
        <clef><sign>G</sign><line>2</line></clef>
      </attributes>
      <note><rest/><duration>4</duration><type>whole</type></note>
    </measure>
  </part>
</score-partwise>'''
                
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(fallback_xml)
                return False
            except Exception as fallback_error:
                print(f"Failed to create fallback MusicXML: {fallback_error}")
                return False

    def _last_non_control(self, seq):
        for t in reversed(seq):
            if t not in self._ids_timeshift and t not in self._ids_micro:
                return t
        return None

    def _apply_syntax_biases(self, seq, logits):
        """å¯¹ä¸‹ä¸€æ­¥ logits æ–½åŠ ç®€å•è¯­æ³•åç½®ï¼Œå‡å°‘ä¼‘æ­¢/ç©ºç™½å¹¶æå‡Pitch/Durationæ¦‚ç‡ã€‚"""
        with torch.no_grad():
            bias = torch.zeros_like(logits)
            last_tok = self._last_non_control(seq)

            # é€šç”¨ï¼šé™ä½è¿ç»­ TimeShift/MicroTiming æ¦‚ç‡
            if len(seq) >= 1 and (seq[-1] in self._ids_timeshift or seq[-1] in self._ids_micro):
                bias[list(self._ids_timeshift)] -= 0.4
                bias[list(self._ids_micro)] -= 0.2

            # è‹¥ä¸Šä¸€ä¸ªéæ§åˆ¶ä¸æ˜¯ Pitchï¼Œåˆ™æ›´å¸Œæœ›ä¸‹ä¸€æ­¥æ˜¯ Pitch
            if last_tok is None or last_tok not in self._ids_pitch:
                bias[list(self._ids_pitch)] += 0.9
                # åŒæ—¶æŠ‘åˆ¶ç»§ç»­TimeShift
                bias[list(self._ids_timeshift)] -= 0.3
                # é¼“åŠ±çŸ­TimeShiftä»¥å‡å°‘é•¿åœé¡¿
                if hasattr(self, '_ids_timeshift_short'):
                    bias[list(self._ids_timeshift_short)] += 0.2
            else:
                # ä¸Šä¸€ä¸ªæ˜¯ Pitchï¼šä¸‹ä¸€æ­¥é¼“åŠ± Velocity æˆ– Durationï¼ˆä¼˜å…ˆç»™å‡ºæ—¶å€¼/åŠ›åº¦ï¼‰
                bias[list(self._ids_velocity)] += 0.5
                bias[list(self._ids_duration)] += 0.8

            # è½¯çº¦æŸï¼šæ§åˆ¶ç±»tokenæ•´ä½“è½»åº¦é™æƒ
            bias[list(self._ids_micro)] -= 0.2

            # å…¨å±€ï¼šæƒ©ç½šé•¿TimeShiftï¼Œé¼“åŠ±çŸ­TimeShift
            if hasattr(self, '_ids_timeshift_long'):
                bias[list(self._ids_timeshift_long)] -= 0.6
            if hasattr(self, '_ids_timeshift_short'):
                bias[list(self._ids_timeshift_short)] += 0.4

            return logits + bias

    def _sanitize_tokens(self, tokens):
        """æ¸…æ´—ç”Ÿæˆåºåˆ—ä»¥æ»¡è¶³ PerTok è¯­æ³•ï¼š
        - ç¡®ä¿å¼€å¤´æœ‰ TimeSig æˆ– BOSï¼ˆè‹¥å­˜åœ¨ï¼‰
        - åˆå¹¶è¿ç»­ TimeShift/MicroTimingï¼ˆä»…ä¿ç•™ä¸€ä¸ªï¼‰
        - ä¸ºæ—  Duration çš„ Pitch è¡¥é»˜è®¤ Duration
        - å»é™¤ç»“å°¾å¤šä½™çš„æ§åˆ¶ç±» token
        """
        vocab = self.tokenizer.vocab
        id_to_str = {v: k for k, v in vocab.items()}

        def default_duration_id():
            # é€‰æ‹©ä¸€ä¸ªå¸¸è§æ—¶å€¼ï¼ˆ0.80.. çº¦åŠæ‹/æ‹ï¼‰ï¼Œå›é€€åˆ°ç¬¬ä¸€ä¸ªDuration
            for tid in self._ids_duration:
                s = id_to_str.get(tid, '')
                if s.startswith('Duration_0.8') or s.startswith('Duration_1'):
                    return tid
            return next(iter(self._ids_duration)) if self._ids_duration else None

        # ä»…ä¿ç•™å…è®¸çš„tokenï¼Œé¿å…PerTokæ— æ³•è§£æçš„â€œotherâ€ç±»
        filtered = [t for t in tokens if t in self._ids_allowed]

        out = []
        # è‹¥æœ‰ TimeSigï¼Œç¡®ä¿æ”¾åœ¨æœ€å‰
        seen_content = False
        for t in filtered:
            if not seen_content and t in self._ids_timesig:
                out.append(t)
                continue
            if t not in self._ids_timeshift and t not in self._ids_micro and t not in self._ids_special:
                seen_content = True
            out.append(t)

        # è‹¥å¼€å¤´æ²¡æœ‰TimeSigä¸”è¯è¡¨æœ‰4/4ï¼Œæ’å…¥ä¸€æš
        if (not out) or (out[0] not in self._ids_timesig):
            if self._id_timesig_44 is not None:
                out.insert(0, self._id_timesig_44)

        # åˆå¹¶è¿ç»­ TimeShift/MicroTiming
        merged = []
        prev_is_ts = False
        prev_is_micro = False
        for t in out:
            if t in self._ids_timeshift:
                if prev_is_ts:
                    continue
                prev_is_ts = True
                prev_is_micro = False
            elif t in self._ids_micro:
                if prev_is_micro:
                    continue
                prev_is_micro = True
                prev_is_ts = False
            else:
                prev_is_ts = prev_is_micro = False
            merged.append(t)

        # äº‹ä»¶çº§é‡æ’ï¼šç¡®ä¿ [Pitch][Velocity?][MicroTiming?][Duration] çš„é¡ºåº
        cleaned = []
        i = 0
        dur_id = default_duration_id()
        while i < len(merged):
            t = merged[i]
            if t in self._ids_pitch:
                pitch_tok = t
                vel_tok = None
                micro_tok = None
                dur_tok = None
                look_end = min(i + 8, len(merged))
                k = i + 1
                while k < look_end:
                    tk = merged[k]
                    if tk in self._ids_velocity and vel_tok is None:
                        vel_tok = tk
                    elif tk in self._ids_micro and micro_tok is None:
                        micro_tok = tk
                    elif tk in self._ids_duration and dur_tok is None:
                        dur_tok = tk
                    elif tk in self._ids_pitch or tk in self._ids_timeshift:
                        break
                    k += 1
                cleaned.append(pitch_tok)
                if vel_tok is not None:
                    cleaned.append(vel_tok)
                if micro_tok is not None:
                    cleaned.append(micro_tok)
                cleaned.append(dur_tok if dur_tok is not None else dur_id)
                # è·³è¿‡å·²æ¶ˆè´¹çš„çª—å£
                i = k
                continue
            else:
                cleaned.append(t)
                i += 1

        # å»é™¤ç»“å°¾å¤šä½™æ§åˆ¶ token
        while cleaned and (cleaned[-1] in self._ids_timeshift or cleaned[-1] in self._ids_micro):
            cleaned.pop()

        # è‹¥æœ‰ BOS/EOS åˆ™è¡¥é½ï¼ˆæœ€åå†è¡¥ï¼‰
        bos = vocab.get('BOS_None')
        eos = vocab.get('EOS_None')
        if bos is not None and (len(cleaned) == 0 or cleaned[0] != bos):
            cleaned.insert(0, bos)
        if eos is not None and cleaned[-1] != eos:
            cleaned.append(eos)

        return cleaned
    def decode_to_midi(self, tokens, output_path):
        """å°†tokenåºåˆ—è§£ç ä¸ºMIDIæ–‡ä»¶å¹¶ä¿å­˜
        
        Args:
            tokens: tokenåºåˆ—
            output_path: è¾“å‡ºMIDIæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: è§£ç æ˜¯å¦æˆåŠŸ
        """
        try:
            print(f"ğŸ¼ è§£ç tokenåºåˆ—ä¸ºMIDI: {len(tokens)}ä¸ªtokens")
            
            # ä½¿ç”¨FixedPerTokDecoderè§£ç 
            score = self.decoder.decode_tokens(tokens)
            if score is None:
                print("âŒ è§£ç å¤±è´¥")
                return False
                
            # è·å–éŸ³ç¬¦æ•°é‡
            total_notes = sum(len(t.notes) for t in getattr(score, 'tracks', []))
            print(f"  âœ… PerTokæ¶æ„è§£ç å®Œæˆ: {total_notes}ä¸ªéŸ³ç¬¦")
            
            # ä¿å­˜MIDIæ–‡ä»¶
            success = self.decoder.save_to_midi(score, output_path)
            if success:
                file_size = os.path.getsize(output_path)
                print(f"âœ… MIDIä¿å­˜æˆåŠŸ: ")
                print(f"   æ–‡ä»¶: {output_path} ({file_size} bytes)")
                print(f"   è½¨é“æ•°: {len(getattr(score, 'tracks', []))}")
                print(f"   éŸ³ç¬¦æ•°: {total_notes}")
                return True
            else:
                print("âŒ MIDIä¿å­˜å¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ MIDIè§£ç å¤±è´¥: {e}")
            return False
            
    def analyze_ornament_content(self, tokens):
        """åˆ†ætokenåºåˆ—ä¸­çš„è£…é¥°éŸ³å†…å®¹"""
        try:
            analyzer = self.ornament_loss.analyzer
            
            analysis = {
                'total_tokens': len(tokens),
                'ornament_tokens': 0,
                'ornament_ratio': 0.0,
                'ornament_categories': {},
                'average_weight': 0.0
            }
            
            weights = []
            for token_id in tokens:
                if token_id < len(self.tokenizer.vocab):
                    weight = analyzer.get_ornament_weight(token_id)
                    weights.append(weight)
                    
                    if analyzer.is_ornament_token(token_id):
                        analysis['ornament_tokens'] += 1
                        
                        # ç»Ÿè®¡è£…é¥°éŸ³ç±»åˆ«
                        for category, token_set in analyzer.ornament_tokens.items():
                            if token_id in token_set:
                                analysis['ornament_categories'][category] = analysis['ornament_categories'].get(category, 0) + 1
            
            if analysis['total_tokens'] > 0:
                analysis['ornament_ratio'] = analysis['ornament_tokens'] / analysis['total_tokens']
                analysis['average_weight'] = sum(weights) / len(weights) if weights else 1.0
            
            return analysis
            
        except Exception as e:
            print(f"âŒ è£…é¥°éŸ³åˆ†æå¤±è´¥: {e}")
            return {}
    
    def generate_from_midi(self, input_path: str, output_path: str, **kwargs):
        """å®Œæ•´çš„MIDIåˆ°MIDIè£…é¥°éŸ³ç”Ÿæˆæµç¨‹"""
        print("ğŸš€ å¼€å§‹å®Œæ•´è£…é¥°éŸ³ç”Ÿæˆæµç¨‹")
        print("=" * 60)
        
        start_time = time.time()
        
        # 1. ç¼–ç è¾“å…¥MIDI
        print("\n1ï¸âƒ£ ç¼–ç è¾“å…¥MIDI")
        input_tokens = self.encode_midi(input_path)
        if input_tokens is None:
            print("âŒ æµç¨‹ç»ˆæ­¢ï¼šMIDIç¼–ç å¤±è´¥")
            return False
        
        # 2. åˆ†æè¾“å…¥å†…å®¹
        print("\n2ï¸âƒ£ åˆ†æè¾“å…¥å†…å®¹")
        input_analysis = self.analyze_ornament_content(input_tokens)
        print(f"   æ€»tokens: {input_analysis['total_tokens']}")
        print(f"   è£…é¥°éŸ³tokens: {input_analysis['ornament_tokens']} ({input_analysis['ornament_ratio']:.1%})")
        print(f"   å¹³å‡æƒé‡: {input_analysis['average_weight']:.2f}")
        
        # 3. ç”Ÿæˆè£…é¥°éŸ³
        print("\n3ï¸âƒ£ ç”Ÿæˆè£…é¥°éŸ³")
        generated_tokens = self.generate_ornaments(input_tokens, **kwargs)
        if generated_tokens is None:
            print("âŒ æµç¨‹ç»ˆæ­¢ï¼šè£…é¥°éŸ³ç”Ÿæˆå¤±è´¥")
            return False
        
        # 4. åˆ†æç”Ÿæˆå†…å®¹
        print("\n4ï¸âƒ£ åˆ†æç”Ÿæˆå†…å®¹")
        output_analysis = self.analyze_ornament_content(generated_tokens)
        print(f"   æ€»tokens: {output_analysis['total_tokens']}")
        print(f"   è£…é¥°éŸ³tokens: {output_analysis['ornament_tokens']} ({output_analysis['ornament_ratio']:.1%})")
        print(f"   å¹³å‡æƒé‡: {output_analysis['average_weight']:.2f}")
        
        # 5. è§£ç ä¸ºMIDI
        print("\n5ï¸âƒ£ è§£ç ä¸ºMIDI")
        decode_success = self.decode_to_midi(generated_tokens, output_path)
        if not decode_success:
            print("âŒ æµç¨‹ç»ˆæ­¢ï¼šMIDIè§£ç å¤±è´¥")
            return False
        
        # 6. æ€»ç»“
        elapsed_time = time.time() - start_time
        ornament_enhancement = output_analysis['ornament_ratio'] - input_analysis['ornament_ratio']
        
        print("\n" + "=" * 60)
        print("ğŸ“Š æµç¨‹å®Œæˆæ€»ç»“")
        print("=" * 60)
        print(f"âœ… è¾“å…¥æ–‡ä»¶: {input_path}")
        print(f"âœ… è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.1f}ç§’")
        print(f"ğŸµ è¾“å…¥è£…é¥°éŸ³: {input_analysis['ornament_ratio']:.1%}")
        print(f"ğŸ¨ è¾“å‡ºè£…é¥°éŸ³: {output_analysis['ornament_ratio']:.1%}")
        print(f"ğŸ“ˆ è£…é¥°éŸ³å¢å¼º: {ornament_enhancement:+.1%}")
        
        if ornament_enhancement > 0:
            print("\nğŸ‰ è£…é¥°éŸ³ç”ŸæˆæˆåŠŸå®Œæˆï¼")
        else:
            print("\nâš ï¸  æ³¨æ„ï¼šç”Ÿæˆçš„è£…é¥°éŸ³æ¯”ä¾‹æœªå¢åŠ ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç”Ÿæˆå‚æ•°")
        
        return True


def main():
    parser = argparse.ArgumentParser(
        description='è£…é¥°éŸ³ç”Ÿæˆæ¨ç† - Leveraging PerTok and Domain-Specific Transformer Design for Expressive MIDI Ornament Generation',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºç¡€ç”Ÿæˆ
  python inference.py --input examples/bach.mid --output output/bach_ornament.mid
  
  # è°ƒæ•´ç”Ÿæˆå‚æ•°
  python inference.py --input input.mid --output output.mid --temperature 1.2 --top_k 50 --top_p 0.9
  
  # ä½¿ç”¨ç‰¹å®šæ¨¡å‹
  python inference.py --model checkpoints_ornament_aware/best_ornament_aware_model.pth --input input.mid --output output.mid
        """)
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--input', '-i', type=str, required=True,
                        help='è¾“å…¥MIDIæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, required=True,
                        help='è¾“å‡ºMIDIæ–‡ä»¶è·¯å¾„')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model', '-m', type=str, 
                        default='checkpoints_ornament_aware/best_ornament_aware_model.pth',
                        help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: æœ€æ–°çš„OrnamentAwareæ¨¡å‹)')
    parser.add_argument('--device', type=str, default='auto',
                        choices=['auto', 'cuda', 'cpu'],
                        help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--allow_fallback', action='store_true', default=False,
                        help='å…è®¸åœ¨PerTokè§£ç å¤±è´¥æ—¶å›é€€åˆ°æ‰‹å†™è§£ç ï¼ˆé»˜è®¤ä¸¥æ ¼æ¨¡å¼ï¼šä¸å›é€€ï¼‰')
    
    # ç”Ÿæˆå‚æ•°
    parser.add_argument('--temperature', '-t', type=float, default=1.1,
                        help='ç”Ÿæˆæ¸©åº¦ (é»˜è®¤: 1.1, èŒƒå›´: 0.5-2.0)')
    parser.add_argument('--top_k', type=int, default=50,
                        help='Top-ké‡‡æ · (é»˜è®¤: 50)')
    parser.add_argument('--top_p', type=float, default=0.9,
                        help='Top-pé‡‡æ · (é»˜è®¤: 0.9)')
    
    # è¾“å‡ºæ§åˆ¶
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='è¯¦ç»†è¾“å‡º')
    parser.add_argument('--force', '-f', action='store_true',
                        help='å¼ºåˆ¶è¦†ç›–è¾“å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return 1
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•
    output_dir = os.path.dirname(args.output)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if os.path.exists(args.output) and not args.force:
        response = input(f"âš ï¸  è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨: {args.output}\næ˜¯å¦è¦†ç›–? (y/N): ")
        if response.lower() not in ['y', 'yes']:
            print("âŒ æ“ä½œå–æ¶ˆ")
            return 1
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(args.model):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²è®­ç»ƒæ¨¡å‹æˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
        return 1
    
    # å‚æ•°éªŒè¯
    if not (0.1 <= args.temperature <= 3.0):
        print(f"âŒ æ¸©åº¦å‚æ•°è¶…å‡ºèŒƒå›´: {args.temperature} (åº”åœ¨0.1-3.0ä¹‹é—´)")
        return 1
    
    if not (1 <= args.top_k <= 200):
        print(f"âŒ top_kå‚æ•°è¶…å‡ºèŒƒå›´: {args.top_k} (åº”åœ¨1-200ä¹‹é—´)")
        return 1
    
    if not (0.1 <= args.top_p <= 1.0):
        print(f"âŒ top_på‚æ•°è¶…å‡ºèŒƒå›´: {args.top_p} (åº”åœ¨0.1-1.0ä¹‹é—´)")
        return 1
    
    try:
        # åˆå§‹åŒ–æ¨ç†å¼•æ“
        engine = OrnamentInferenceEngine(args.model, args.device, allow_fallback=args.allow_fallback)
        
        # ç”Ÿæˆè£…é¥°éŸ³
        success = engine.generate_from_midi(
            input_path=args.input,
            output_path=args.output,
            temperature=args.temperature,
            top_k=args.top_k,
            top_p=args.top_p
        )
        
        return 0 if success else 1
        
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
